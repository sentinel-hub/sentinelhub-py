{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel Hub Batch Processing V2\n",
    "\n",
    "*(This guide is for the new version 2 of the Batch Process API)*\n",
    "\n",
    "**Sentinel Hub Batch Processing** takes the geometry of a large area and divides it according to a specified tile grid. Next, it executes processing requests for each tile in the grid and stores results to a given location at AWS S3 storage. All this is efficiently executed on the server-side. Because of the optimized performance, it is significantly faster than running the same process locally. \n",
    "\n",
    "More information about batch processing is available at Sentinel Hub documentation pages:\n",
    "\n",
    "- [How Batch V2 API works](https://docs.sentinel-hub.com/api/latest/api/batchv2/)\n",
    "- [Batch V2 API service description](https://docs.sentinel-hub.com/api/latest/reference/#tag/batch_v2_process)\n",
    "\n",
    "\n",
    "The tutorial will show a standard process of using Batch Processing with `sentinelhub-py`. The process can be divided into:\n",
    "\n",
    "1. Define and create a batch request\n",
    "2. Analyse a batch request before it is executed\n",
    "3. Run a batch requests job and check the outcome\n",
    "\n",
    "**Imports**\n",
    "\n",
    "The tutorial requires the package `geopandas` which is not a dependency of `sentinelhub-py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "from sentinelhub import (\n",
    "    CRS,\n",
    "    BatchProcessClient,\n",
    "    DataCollection,\n",
    "    Geometry,\n",
    "    MimeType,\n",
    "    SentinelHubRequest,\n",
    "    SHConfig,\n",
    "    bbox_to_dimensions,\n",
    "    monitor_batch_process_job,\n",
    ")\n",
    "\n",
    "# The following is not a package. It is a file utils.py which should be in the same folder as this notebook.\n",
    "from utils import plot_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a batch request\n",
    "\n",
    "To create a batch request we need to do the following:\n",
    "\n",
    "- Define a Process API request which we would like to execute on a large area.\n",
    "- Select a tiling grid which will define how our area will be split into smaller tiles.\n",
    "- Set up an S3 bucket where results will be saved.\n",
    "\n",
    "\n",
    "### 1.1 Define a Process API request\n",
    "\n",
    "First, let's set up the credentials the same way as in [Sentinel Hub Process API tutorial](./process_request.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SHConfig()\n",
    "\n",
    "if config.sh_client_id == \"\" or config.sh_client_secret == \"\":\n",
    "    print(\"Warning! To use Sentinel Hub Process API, please provide the credentials (client ID and client secret).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our area of interest, we'll take an area of crop fields in California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE_PATH = os.path.join(\".\", \"data\", \"california_crop_fields.geojson\")\n",
    "area_gdf = gpd.read_file(SHAPE_PATH)\n",
    "\n",
    "# Geometry of an entire area\n",
    "full_geometry = Geometry(area_gdf.geometry.values[0], crs=CRS.WGS84)\n",
    "# Bounding box of a test sub-area\n",
    "test_bbox = Geometry(area_gdf.geometry.values[1], crs=CRS.WGS84).bbox\n",
    "\n",
    "area_gdf.plot(column=\"name\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check a true-color satellite image of the entire area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalscript_true_color = \"\"\"\n",
    "    //VERSION=3\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"B02\", \"B03\", \"B04\"]\n",
    "            }],\n",
    "            output: {\n",
    "                bands: 3\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "    function evaluatePixel(sample) {\n",
    "        return [sample.B04, sample.B03, sample.B02];\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "request = SentinelHubRequest(\n",
    "    evalscript=evalscript_true_color,\n",
    "    input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L2A,\n",
    "        )\n",
    "    ],\n",
    "    responses=[SentinelHubRequest.output_response(\"default\", MimeType.PNG)],\n",
    "    geometry=full_geometry,\n",
    "    size=(512, 512),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "image = request.get_data()[0]\n",
    "\n",
    "plot_image(image, factor=3.5 / 255, clip_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define an evalscript and time range. To better demonstrate the power of batch processing we'll take an evalscript that returns a temporally-interpolated stack NDVI values.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Warning:</b>\n",
    "    \n",
    "In the following cell parameters `evalscript` and `time_interval` are both defined for the same time interval. If you decide to change the time interval you have to change it both in the cell and in the evalscript code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALSCRIPT_PATH = os.path.join(\".\", \"data\", \"interpolation_evalscript.js\")\n",
    "\n",
    "with open(EVALSCRIPT_PATH) as fp:\n",
    "    evalscript = fp.read()\n",
    "\n",
    "time_interval = dt.date(year=2020, month=7, day=1), dt.date(year=2020, month=7, day=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a Process API request and test it on a smaller sub-area to make sure we get back desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sentinelhub_request = SentinelHubRequest(\n",
    "    evalscript=evalscript,\n",
    "    input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L1C,\n",
    "            time_interval=time_interval,\n",
    "        )\n",
    "    ],\n",
    "    responses=[\n",
    "        SentinelHubRequest.output_response(\"NDVI\", MimeType.TIFF),\n",
    "        SentinelHubRequest.output_response(\"data_mask\", MimeType.TIFF),\n",
    "    ],\n",
    "    bbox=test_bbox,\n",
    "    size=bbox_to_dimensions(test_bbox, 10),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "results = sentinelhub_request.get_data()[0]\n",
    "\n",
    "print(f\"Output data: {list(results)}\")\n",
    "\n",
    "plot_image(results[\"NDVI.tif\"][..., 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained stacks of NDVI values and data masks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define a batch client\n",
    "\n",
    "The interface for Sentinel Hub Batch API is class `BatchProcessClient`. We initialize it with a configuration object that contains credentials and URLs of the services.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Note:</b>\n",
    "    \n",
    "The `BatchProcessClient` interface uses the Version 2 API of batch processing. `SentinelHubBatch` is the client for Version 1.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = BatchProcessClient(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Select a tiling grid\n",
    "\n",
    "Batch API offers a number of pre-defined tiling grids. We can check which ones are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(client.iter_tiling_grids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select a 10km grid, which is based on Sentinel-2 data tiling grid in UTM coordinate reference systems.\n",
    "\n",
    "There is also an option to check a definition for a single grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify grid ID here:\n",
    "GRID_ID = 1\n",
    "\n",
    "client.get_tiling_grid(GRID_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Set up an S3 bucket\n",
    "\n",
    "For this step please follow [instructions](https://docs.sentinel-hub.com/api/early-access/api/early-access-batchv2/#aws-bucket-access) on how to provide a way for the Batch Process to write to your S3 bucket. We suggest using the *AWS IAM Assume Role Workflow*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_PATH = \"???\"\n",
    "\n",
    "ROLE_ARN = \"???\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Join batch request definition\n",
    "\n",
    "Now we are ready to create an entire batch request. This step won't trigger the actual processing. It will only save a batch request definition to the server-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentinelhub_request = SentinelHubRequest(\n",
    "    evalscript=evalscript,\n",
    "    input_data=[\n",
    "        SentinelHubRequest.input_data(\n",
    "            data_collection=DataCollection.SENTINEL2_L1C,\n",
    "            time_interval=time_interval,\n",
    "        )\n",
    "    ],\n",
    "    responses=[\n",
    "        SentinelHubRequest.output_response(\"NDVI\", MimeType.TIFF),\n",
    "        SentinelHubRequest.output_response(\"data_mask\", MimeType.TIFF),\n",
    "    ],\n",
    "    geometry=full_geometry,\n",
    "    # This time we don't specify size parameter\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "batch_request = client.create(\n",
    "    sentinelhub_request,\n",
    "    input=client.tiling_grid_input(grid_id=GRID_ID, resolution=10, buffer_x=50, buffer_y=50),\n",
    "    output=client.raster_output(\n",
    "        delivery=client.s3_specification(BUCKET_PATH, iam_role_arn=ROLE_ARN, region=\"eu-central-1\")\n",
    "    ),\n",
    "    description=\"sentinelhub-py tutorial batch job\",\n",
    ")\n",
    "\n",
    "batch_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A batch request has been successfully created. The information about a request is provided in the form of a `BatchProcessRequest` dataclass object. From the object representation, we can see some of its main properties, such as `status`, which defines the current status of a batch request. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you can write down your batch request ID. In case you restart your Python kernel or delete `batch_request` object you can always re-initialize it with the request ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your batch_request.request_id here\n",
    "REQUEST_ID = \"???\"\n",
    "\n",
    "client.get_request(REQUEST_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse a batch request\n",
    "\n",
    "Before we run a batch request job we can check currently defined batch requests and run an analysis to determine the outcome of a batch request. This step is also run automatically if we just run the batch request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Investigate past batch requests\n",
    "\n",
    "We already have our current batch request definition in `batch_request` variable. However, if we would like to find it again we can search the history of all created batch requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for request in client.iter_requests():\n",
    "    print(request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Run an analysis\n",
    "\n",
    "At the moment we don't have information about tiles or processing units yet. But we can order the service to calculate it.\n",
    "\n",
    "The following will start the analysis on the server-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.start_analysis(batch_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the size of our batch request it might take from a few seconds to a few minutes for analysis to finish. To determine if the analysis has finished we have to update batch request info and check the `status` information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_request = client.get_request(batch_request)\n",
    "\n",
    "batch_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run a batch request job\n",
    "\n",
    "Once we decide to run a batch request job we can trigger it with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.start_job(batch_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can check if a job has finished by updating batch request info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_request = client.get_request(batch_request)\n",
    "\n",
    "batch_request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package also provides a utility function that monitors batch job execution by periodically checking for status and sleeping in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_batch_process_job(batch_request, client, sleep_time=60)  # It will update progress every 60 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to check which results have already been saved to the given S3 bucket.\n",
    "\n",
    "When the job is running we can decide at any time to cancel it. Results that have already been produced will remain on the bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.stop_job(batch_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Alternative inputs/outputs\n",
    "\n",
    "Apart from using the predefined tiling grids, one can also provide the grid via GeoPackage. Details on how the GPKG must be structured can be found [here](https://docs.sentinel-hub.com/api/early-access/api/early-access-batchv2/#2-geopackage). To construct a suitable `input` for the request, you can use `client.geopackage_input` instead of `client.tiling_grid_input`.\n",
    "\n",
    "The batch process also supports [Zarr format output](https://docs.sentinel-hub.com/api/early-access/api/early-access-batchv2/#2-zarr-output-format). To construct a suitable `output` field switch `client.raster_output` with `client.zarr_output` when creating the batch request"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
